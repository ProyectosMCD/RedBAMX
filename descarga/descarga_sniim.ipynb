{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68yOgpwhj2xJ"
      },
      "source": [
        "# Descarga de datos del SNIIM (Sistema Nacional de información e Integración de Mercados)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQ2ao2LRYshN"
      },
      "source": [
        "El **SNIIM** proporciona información de precios al mayoreo del mercado agroalimentario a fin de coadyuvar a la toma de decisiones en materia de comercio, así como también brinda una atención a los usuarios con apego al marco legal aplicable, comprometidos en la mejora continua.\n",
        "\n",
        "No se encontraron los datos disponibles en descarga directa, tampoco a través de APIs, por lo tanto se hace necesario realizar ***web scraping*** para la automatización y descarga de los datos.\n",
        "\n",
        "<br>\n",
        "\n",
        "Por ahora sólo se realiza la descarga para la categoría de **\"Frutas y Hortalizas\"**, las cuales son las de interés en este momento para la **Red de Banco de Alimentos (RedBAMx).**\n",
        "\n",
        "Los parámetros por default para la descarga son los siguientes:\n",
        "- Intervalo de fechas: **01/01/2020 al 31/12/2023**\n",
        "- Precio por: **Kilogramo**\n",
        "- Lista de productos de interés:\n",
        "  \n",
        "        ['Berenjena', 'Brócoli', 'Calabacita', 'Cebolla', 'Chile Anaheim', 'Chile California', 'Chile Bola', 'Chile Caloro',\n",
        "        'Chile Caribe', 'Chile Cat', 'Chile Chilaca', 'Chile de Árbol fresco', 'Chile Dulce', 'Chile Habanero', 'Chile Húngaro',\n",
        "        'Chile Mirasol', 'Chile Jalapeño', 'Chile Pimiento morrón', 'Chile Poblano', 'Chile Puya fresco', 'Chile Serrano',\n",
        "        'Coliflor', 'Durazno', 'Espárrago', 'Frambuesa', 'Fresa', 'Guayaba', 'Jitomate', 'Lechuga', 'Limón', 'Mango',\n",
        "        'Manzana', 'Melón', 'Naranja', 'Nopal', 'Nuez', 'Papa', 'Papaya', 'Pepino', 'Pera', 'Piña', 'Plátano', 'Sandía',\n",
        "        'Tomate Verde', 'Toronja', 'Uva', 'Zarzamora']\n",
        "\n",
        "<br>\n",
        "\n",
        "*Basado en el scraper hecho por México Abierto:*\n",
        "https://github.com/mxabierto/scraper-sniim/blob/master/sniim/precios_historicos.py\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Montar google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFiaj8cACKXQ",
        "outputId": "805996d9-02c0-423b-8dea-760dee495b9f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTwMTbU8j2xO"
      },
      "source": [
        "## Importar librerías"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "XjuACWQ0DRcL"
      },
      "outputs": [],
      "source": [
        "# Importar librerías\n",
        "\n",
        "import re\n",
        "import csv\n",
        "from bs4 import BeautifulSoup\n",
        "import urllib.request\n",
        "#from urllib.error import HTTPError\n",
        "\n",
        "import os\n",
        "from datetime import datetime, timedelta\n",
        "import pandas as pd\n",
        "import logging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hIR8QVWu90R"
      },
      "source": [
        "Se configura módulo logging para crear log de descargas, según documentación https://docs.python.org/es/3/howto/logging.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "1gvA4zWBouda"
      },
      "outputs": [],
      "source": [
        "#logger = logging.getLogger('my_logger')\n",
        "logging.basicConfig(\n",
        "    filename='./descarga.log',\n",
        "    filemode='a',\n",
        "    encoding='utf-8',\n",
        "    format='%(asctime)s, %(levelname)s %(message)s',\n",
        "    datefmt='%d/%m/%Y %I:%M:%S %p',\n",
        "    level=logging.DEBUG,\n",
        "    force=True # Resets any previous configuration\n",
        ")\n",
        "\n",
        "#logging.debug('This message should go to the log file')\n",
        "#logging.info('So should this')\n",
        "#logging.warning('And this, too')\n",
        "#logging.error('And non-ASCII stuff, too, like Øresund and Malmö')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ne3Yyf83j2xQ"
      },
      "source": [
        "Se crean las carpetas para almacenar archivos temporales y de salida"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "SzgvDiVcFi94"
      },
      "outputs": [],
      "source": [
        "# Creación de carpetas temporales y de salida\n",
        "#print(os.getcwd())\n",
        "path = \"./drive/MyDrive/\"\n",
        "subdir1 = path + 'temp/'\n",
        "subdir2 = path + 'raw_data/'\n",
        "\n",
        "try:\n",
        "  if not os.path.exists(subdir1):\n",
        "    os.makedirs(subdir1)\n",
        "  if not os.path.exists(subdir2):\n",
        "    os.makedirs(subdir2)\n",
        "except Exception as e:\n",
        "        print (\"Error al crear carpeta: \", e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOCdOomHj2xQ"
      },
      "source": [
        "Esta función realiza el web scraping a partir de la URL del producto que recibe. Extrae la tabla con la información de los precios y la guarda en un archivo CSV."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "JyEL5aCz0NFt"
      },
      "outputs": [],
      "source": [
        "# Función que realiza el scrapping para extraer una tabla de información y  guardarla en archivo CSV\n",
        "def creaTabla(url, archivo_salida, paginacion, categoria):\n",
        "    print (url, archivo_salida, paginacion, categoria)\n",
        "    try:\n",
        "\n",
        "        with urllib.request.urlopen(url+str(paginacion), timeout=500) as response, \\\n",
        "          open(path + 'temp/' + archivo_salida, 'wb') as out_file, \\\n",
        "          open(path + 'raw_data/' + archivo_salida + \".csv\", 'w', newline=\"\\n\") as csvfile:\n",
        "\n",
        "            data = response.read().decode('utf-8').encode('utf-8')\n",
        "            soup = BeautifulSoup(data)\n",
        "\n",
        "\n",
        "            try:\n",
        "              paginas = soup.find('span', attrs={\"id\":\"lblPaginacion\"}).get_text()\n",
        "              print(paginas, paginas != 'Página  1 de  1')\n",
        "\n",
        "              total_paginas = paginas.split(' ')[-1]\n",
        "\n",
        "              # Si el resultado excede a una página, entonces se vuelve a llamar la función calculando\n",
        "              # paginación = número de registros por página * número total de páginas\n",
        "              # con la finalidad de extraer el total de registros en un solo request\n",
        "              if total_paginas != '1':\n",
        "                  return creaTabla(url, archivo_salida, paginacion * int(total_paginas), categoria)\n",
        "              out_file.write(data)\n",
        "\n",
        "\n",
        "              table = soup.find('table',attrs={\"id\":\"tblResultados\"})\n",
        "\n",
        "              spamwriter = csv.writer(csvfile, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
        "\n",
        "              for row in table.find_all(\"tr\"):\n",
        "                  x = [td.get_text() for td in row.find_all(\"td\")]\n",
        "                  spamwriter.writerow(x)\n",
        "\n",
        "\n",
        "            except:\n",
        "              print ('La página no tiene tabla, ', url, paginacion)\n",
        "\n",
        "              #borrar archivos\n",
        "              if os.path.exists(path + \"raw_data/\" + archivo_salida + \".csv\"):\n",
        "                csvfile.close()\n",
        "                os.remove(path + \"raw_data/\" + archivo_salida + \".csv\")\n",
        "              if os.path.exists(path + \"temp/\" + archivo_salida):\n",
        "                out_file.close()\n",
        "                os.remove(path + \"temp/\" + archivo_salida)\n",
        "              pass\n",
        "    except Exception as e:\n",
        "      print (\"Error: \", url,e)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uwy19hMnl6_C"
      },
      "source": [
        "## Descarga automatizada de los datos\n",
        "\n",
        "Se define la **lista de productos** de interés por descargar, así como también la **modalidad de los precios** (por presentación comercial o por kilogramo) y el **intervalo de fechas** deseado.\n",
        "\n",
        "Una vez definidos estos parámetros, se procede a la descarga de los datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vSlrJGXZcloU",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "logging.info('Descarga de datos SNIIM iniciada.')\n",
        "\n",
        "# Se define lista de productos de interés\n",
        "lista_productos = ['Berenjena', 'Brócoli', 'Calabacita', 'Cebolla', 'Chile Anaheim', 'Chile California', 'Chile Bola', 'Chile Caloro',\n",
        "                  'Chile Caribe', 'Chile Cat', 'Chile Chilaca', 'Chile de Árbol fresco', 'Chile Dulce', 'Chile Habanero', 'Chile Húngaro',\n",
        "                  'Chile Mirasol', 'Chile Jalapeño', 'Chile Pimiento morrón', 'Chile Poblano', 'Chile Puya fresco', 'Chile Serrano',\n",
        "                  'Coliflor', 'Durazno', 'Espárrago', 'Frambuesa', 'Fresa', 'Guayaba', 'Jitomate', 'Lechuga', 'Limón', 'Mango',\n",
        "                  'Manzana', 'Melón', 'Naranja', 'Nopal', 'Nuez', 'Papa', 'Papaya', 'Pepino', 'Pera', 'Piña', 'Plátano', 'Sandía',\n",
        "                  'Tomate Verde', 'Toronja', 'Uva', 'Zarzamora']\n",
        "\n",
        "# Se define si los precios se requieren por 1: Presentación comercial ó 2: Kilogramo calculado\n",
        "precios_por = 2\n",
        "\n",
        "# Se definen las fechas de búsqueda\n",
        "str_fecha_inicio = \"01/01/2020\"\n",
        "str_fecha_final = \"30/12/2023\"\n",
        "\n",
        "# Se convierten a tipo date\n",
        "dt_fecha_inicio = datetime.strptime(str_fecha_inicio, '%d/%m/%Y')\n",
        "dt_fecha_final = datetime.strptime(str_fecha_final, '%d/%m/%Y')\n",
        "\n",
        "# Se define un intervalo máximo de años para hacer la descarga en un solo request o en varios\n",
        "max_intervalo_años = 5\n",
        "\n",
        "# Ligas a precios\n",
        "mapa_precios_url = \"http://www.economia-sniim.gob.mx/mapa.asp\"\n",
        "base_url = 'http://www.economia-sniim.gob.mx/Nuevo/Consultas/MercadosNacionales/PreciosDeMercado/Agricolas'\n",
        "frutas_hortalizas_endpoint = \"/ResultadosConsultaFechaFrutasYHortalizas.aspx\"\n",
        "\n",
        "# Se realiza un request para obtener las URL de los productos y se realiza el scraping\n",
        "with urllib.request.urlopen(mapa_precios_url) as response, \\\n",
        "  open(path + 'mapa.aspx', 'wb') as out_file:\n",
        "    data = response.read()#.decode('utf-8').encode('utf-8') # a `bytes` object\n",
        "    out_file.write(data)\n",
        "    soup_directorio = BeautifulSoup(data)\n",
        "\n",
        "    for anchor in soup_directorio.findAll('a', string=re.compile(\"Precio\\sde\\s(?!la|los|Granos)\\w+\")):\n",
        "        producto_id = re.search(r\"ProductoId=(\\d+)\", anchor['href']).group(1)\n",
        "        nombre_producto = anchor.string.replace(\"Precio de \", \"\") # se elimina el prefijo\n",
        "\n",
        "        # Si el nombre de lista contiene \"/\" se reemplaza por \"_\" para prevenir error al crear archivos con este nombre\n",
        "        if \"/\" in nombre_producto:\n",
        "            nombre_producto = nombre_producto.replace(\"/\", \"_\")\n",
        "\n",
        "        #Descomentar para descargar/debuggear un producto específico\n",
        "        #if nombre_producto == \"Guayaba\":\n",
        "\n",
        "        # Si el producto es de interés, se descarga\n",
        "        if any(p in nombre_producto for p in lista_productos):\n",
        "\n",
        "          # Si el periodo de tiempo es mayor a 5 años, se descarga por segmentos de 5 años para prevenir error en el servidor de datos\n",
        "          if(dt_fecha_final.year - dt_fecha_inicio.year) > max_intervalo_años:\n",
        "            for anio_inicio in range(dt_fecha_inicio.year, dt_fecha_final.year, max_intervalo_años):\n",
        "              # Si el año es mayor que el año de la fecha final, se toma el de la fecha final\n",
        "              if(anio_inicio + (max_intervalo_años-1)) > dt_fecha_final.year:\n",
        "                anio_final = dt_fecha_final.year\n",
        "              else:\n",
        "                anio_final = anio_inicio + (max_intervalo_años-1)\n",
        "\n",
        "              url = base_url + frutas_hortalizas_endpoint + f\"?ProductoId={producto_id}&fechaInicio=01/01/{anio_inicio}&fechaFinal=31/12/{anio_final}&PreciosPorId={precios_por}&RegistrosPorPagina=\"\n",
        "              #print(url)\n",
        "\n",
        "              if(url.find(\"http:\") >= 0):\n",
        "                creaTabla(url, nombre_producto.replace(\" \",\"_\") + \"_\" + str(anio_inicio) + \"-\" +str(anio_final), 1000, nombre_producto.replace(\" \",\"_\"))\n",
        "\n",
        "\n",
        "          # De lo contrario, si el periodo de tiempo es menor a 5 años, se descarga en un solo segmento\n",
        "          else:\n",
        "              url = base_url + frutas_hortalizas_endpoint + f\"?ProductoId={producto_id}&fechaInicio={str_fecha_inicio}&fechaFinal={str_fecha_final}&PreciosPorId={precios_por}&RegistrosPorPagina=\"\n",
        "              #print(url)\n",
        "\n",
        "              if(url.find(\"http:\") >= 0):\n",
        "                creaTabla(url, nombre_producto.replace(\" \",\"_\") + \"_\" + str(dt_fecha_inicio.year) + \"-\" + str(dt_fecha_final.year), 1000, nombre_producto.replace(\" \",\"_\"))\n",
        "\n",
        "print(\"Descarga finalizada.\")\n",
        "logging.info('Descarga de datos SNIIM finalizada.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "hTMCgFfJpo87"
      },
      "outputs": [],
      "source": [
        "info = \"\"\"\n",
        "        El SNIIM proporciona información de precios al mayoreo del mercado agroalimentario\n",
        "        a fin de coadyuvar a la toma de decisiones en materia de comercio.\n",
        "\n",
        "        Se realiza web scrapping utilizando las siguientes URLs:\n",
        "        http://www.economia-sniim.gob.mx/mapa.asp\n",
        "        http://www.economia-sniim.gob.mx/Nuevo/Consultas/MercadosNacionales/PreciosDeMercado/Agricolas/ResultadosConsultaFechaFrutasYHortalizas.aspx\n",
        "\n",
        "\n",
        "        \"\"\"\n",
        "logging.info(info)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "egaHwqli8f-I"
      },
      "outputs": [],
      "source": [
        "# Se comprimen los archivos CSV en .zip\n",
        "!zip -r /content/raw_data.zip /content/drive/MyDrive/raw_data\n",
        "\n",
        "# Se descarga el archivo .zip\n",
        "from google.colab import files\n",
        "files.download(\"/content/raw_data.zip\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}